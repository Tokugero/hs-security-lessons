# Install prerequisites on all hosts
#############################################
- name: Add apt_key
  block:
    - name: K8S Repo
      get_url: 
        url: https://pkgs.k8s.io/core:/stable:/v{{ k8s_version }}/deb/Release.key
        dest: /etc/apt/keyrings/kubernetes-apt-keyring.asc

    - name: Add repository
      apt_repository:
        filename: kubernetes.list
        repo: deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.asc] https://pkgs.k8s.io/core:/stable:/v{{ k8s_version }}/deb/ /
        state: present

- name: Install/Update k8s packages
  apt:
    pkg:
      - conntrack
      - ethtool
      - iproute2
      - iptables
      - kubelet={{ k8s_version }}.1-1.1
      - kubeadm={{ k8s_version }}.1-1.1
      - kubectl={{ k8s_version }}.1-1.1
      - python3-kubernetes
    state: present

- name: Hold kubelet
  dpkg_selections:
    name: kubelet
    selection: hold

- name: Hold kubeadm
  dpkg_selections:
    name: kubeadm
    selection: hold

- name: Hold kubectl
  dpkg_selections:
    name: kubectl
    selection: hold

- name: Disable swap
  command: /usr/sbin/swapoff -a

- name: Update fstab
  lineinfile:
    dest: /etc/fstab
    regexp: '^(UUID=.*swap.*)'
    line: '# \1'
    backrefs: yes
    state: present

#############################################
# Setup with kubeadm
#############################################

- name: If node is controller, check if cluster is established and create cluster otherwise
  when: inventory_hostname in groups["controllers"]
  block:
    - name: Check if cluster is established
      stat:
        path: /etc/kubernetes/admin.conf
      register: kubeadmn_init

    - name: Create cluster if not created
      shell: kubeadm init --pod-network-cidr={{ k8s_cidr }}
      when: kubeadmn_init.stat.exists == false

    - name: Generate token just in case we need it for the next task
      shell: kubeadm token create --print-join-command
      register: kubeadm_token_create

- name: If node is worker, check if cluster is established and join cluster otherwise
  when: inventory_hostname in groups["workers"]
  block:
    - name: Check if cluster is established
      stat: 
        path: /etc/kubernetes/kubelet.conf
      register: kubeadm_join

    - name: Join cluster if not joined
      shell: "{{ hostvars[item].kubeadm_token_create.stdout_lines[0] }}"
      with_items: "{{ groups['controllers'] }}"
      when: kubeadm_join.stat.exists == false

- name: Clean up kubeadm token
  when: inventory_hostname in groups["controllers"]
  block:
    - name: Get token list
      shell: kubeadm token list
      register: kubeadm_token_list

    - name: Delete token
      shell: kubeadm token delete {{ kubeadm_token_list.stdout_lines[1].split()[0] }}

#############################################
# Setup with core infrastructure
#############################################

- name: Deploy flannel
  when: inventory_hostname in groups["controllers"]
  block:
    - name: Create flannel
      shell: kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml #https://github.com/flannel-io/flannel

    - name: Wait for flannel to be ready
      shell: kubectl get pods -n kube-flannel -l app=flannel -o jsonpath='{.items[0].status.conditions[?(@.type=="Ready")].status}'
      register: flannel_ready
      until: flannel_ready.stdout == "True"
      retries: 10
      delay: 10

- name: Deploy metallb
  when: inventory_hostname in groups["controllers"]
  block:
  - name: Deploy metallb with defaults
    shell: kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.13.12/config/manifests/metallb-native.yaml

  - name: Metallb namespace
    kubernetes.core.k8s:
      api_version: v1
      kind: Namespace
      state: present
      name: metallb-system

  - name: Configure metallb pool
    kubernetes.core.k8s:
      state: present
      template: metallb-config.yml.j2

- name: Deploy kubevirt
  when: inventory_hostname in groups["controllers"]
  block:
    - name: Install kubevirt
      shell: |
        kubectl apply -f https://github.com/kubevirt/kubevirt/releases/download/{{ lookup('ansible.builtin.url', 'https://storage.googleapis.com/kubevirt-prow/release/kubevirt/kubevirt/stable.txt') }}/kubevirt-operator.yaml
        kubectl apply -f https://github.com/kubevirt/kubevirt/releases/download/{{ lookup('ansible.builtin.url', 'https://storage.googleapis.com/kubevirt-prow/release/kubevirt/kubevirt/stable.txt') }}/kubevirt-cr.yaml

    - name: Wait for kubevirt to complete
      shell: kubectl -n kubevirt wait kv kubevirt --for condition=Available
      register: kubevirt_ready
      until: kubevirt_ready.stdout == "kubevirt.kubevirt.io/kubevirt condition met"
      retries: 10
      delay: 20
      
#############################################
# Pass around credentials for access to cluster
#############################################

- name: Steal admin config from controller for a bit
  when: inventory_hostname in groups["controllers"]
  block:
  - name: Get config from controller
    slurp:
      src: /etc/kubernetes/admin.conf
    register: kubeconfig

  - name: Create .kube if not exists
    become: false
    delegate_to: localhost
    file:
      path: ~/.kube
      state: directory

  - name: Clean kubeconfig
    become: false
    delegate_to: localhost
    file:
      path: ~/.kube/config.hscluster
      state: absent

  - name: Copy kubeconfig to local
    become: false
    delegate_to: localhost
    copy:
      content: "{{ kubeconfig.content | b64decode | string }}"
      dest: ~/.kube/config.hscluster

  - name: Create remote config path
    file:
      path: /root/.kube
      state: directory

  - name: Copy kubeconfig to remote for future scripts
    copy:
      content: "{{ kubeconfig.content | b64decode | string }}"
      dest: /root/.kube/config

  - name: Replace IP
    become: false
    delegate_to: localhost
    replace:
      path: ~/.kube/config.hscluster
      regexp: "0.0.0.0"
      replace: "{{ ansible_default_ipv4.address }}"

  - name: Replace CA
    become: false
    delegate_to: localhost
    replace:
      path: ~/.kube/config.hscluster
      regexp: "certificate-authority-data.*"
      replace: "insecure-skip-tls-verify: true"